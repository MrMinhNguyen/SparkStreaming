{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Producer for Processor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Producing the data\n",
    "### 1.1. Process Event Producer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to read CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The CSV data file is read using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CSV reading function\n",
    "def read_csv(fileName):\n",
    "    # Read the file using Pandas \n",
    "    data = pd.read_csv(fileName)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Kafka functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to publish messages\n",
    "def publish_message(producer_instance, topic_name, data):\n",
    "    # Send message containing data to the specified topic\n",
    "    try:\n",
    "        producer_instance.send(topic_name, data)\n",
    "        print('Message successfully sent. Sent ', len(data['data']), ' rows. At ', data['ts'])\n",
    "    \n",
    "    # If encounters error then print out the error message\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The producer is created at port 9092 and would send messages to the specified topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to generate Kafka producer\n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    \n",
    "    # Generate the connection at port 9092\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                                  value_serializer=lambda x: dumps(x).encode('ascii'),\n",
    "                                  api_version=(0, 10))\n",
    "        \n",
    "    # If encounters error then print out the error message\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "        \n",
    "    # Return the producer\n",
    "    finally:\n",
    "        return _producer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Run the producer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Process Producer is generated at port 9092 and would produce messages to the `process` topic. Data included in each message is extracted from the `Streaming_Linux_process.csv` file. In each iteration, a random number of records for each machine are extracted and included in the message together with the current timestamp. The timestamp comes in the form of Unix format.\n",
    "\n",
    "\n",
    "* The execution of this producer is carried out infinitely and could only be stopped with a keyboard interruption from user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message successfully sent. Sent  155  rows. At  1603783048\n",
      "Message successfully sent. Sent  121  rows. At  1603783053\n",
      "Message successfully sent. Sent  152  rows. At  1603783058\n",
      "Message successfully sent. Sent  145  rows. At  1603783063\n",
      "Message successfully sent. Sent  127  rows. At  1603783068\n",
      "Message successfully sent. Sent  176  rows. At  1603783073\n",
      "Message successfully sent. Sent  137  rows. At  1603783078\n",
      "Message successfully sent. Sent  150  rows. At  1603783083\n",
      "Message successfully sent. Sent  130  rows. At  1603783088\n",
      "Message successfully sent. Sent  143  rows. At  1603783093\n",
      "Message successfully sent. Sent  104  rows. At  1603783098\n",
      "Message successfully sent. Sent  145  rows. At  1603783103\n",
      "Message successfully sent. Sent  133  rows. At  1603783108\n",
      "Message successfully sent. Sent  173  rows. At  1603783113\n",
      "Message successfully sent. Sent  154  rows. At  1603783118\n",
      "Message successfully sent. Sent  153  rows. At  1603783123\n",
      "Message successfully sent. Sent  146  rows. At  1603783128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62197da160b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Rest for 5 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the main program\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Specify the topic\n",
    "    topic = 'process'\n",
    "    \n",
    "    # Read data from the CSV file\n",
    "    all_machines = read_csv('data/Streaming_Linux_process.csv')\n",
    "    \n",
    "    # Split the dataframe into sub-dataframes by machine number\n",
    "    machine_4 = all_machines[all_machines.machine==4].sort_values(by=['sequence'])\n",
    "    machine_5 = all_machines[all_machines.machine==5].sort_values(by=['sequence'])\n",
    "    machine_6 = all_machines[all_machines.machine==6].sort_values(by=['sequence'])\n",
    "    machine_7 = all_machines[all_machines.machine==7].sort_values(by=['sequence'])\n",
    "    machine_8 = all_machines[all_machines.machine==8].sort_values(by=['sequence'])\n",
    "    \n",
    "    # Combine sub-dataframes with their sequence tracking counter\n",
    "    data_tracking = [ [machine_4, 0], [machine_5, 0], [machine_6, 0], [machine_7, 0], [machine_8, 0] ]\n",
    "    \n",
    "    # Create the producer\n",
    "    producer = connect_kafka_producer()\n",
    "    \n",
    "    # Start sending messages\n",
    "    while True:\n",
    "        \n",
    "        # Store data for each message in a list\n",
    "        rows = list()\n",
    "        \n",
    "        # Get records for each machine\n",
    "        for idx in range(len(data_tracking)):\n",
    "            \n",
    "            # Take the dataset and its sequence tracking counter\n",
    "            dataset = data_tracking[idx][0]\n",
    "            counter = data_tracking[idx][1]\n",
    "            \n",
    "            # Get size of the dataset\n",
    "            dataset_size = len(dataset)\n",
    "            \n",
    "            # Create a random number X from 10 to 50\n",
    "            X = random.randint(10, 50)\n",
    "            \n",
    "            # If the data is exhausted then restart from the beginning\n",
    "            if(counter+X >= dataset_size):\n",
    "                # Take the remaining rows and the ones in the beginning\n",
    "                records = pd.concat([dataset.iloc[counter:dataset_size], dataset.iloc[0:counter+X-dataset_size]])\n",
    "                # Reset sequence tracking counter\n",
    "                data_tracking[idx][1] = counter+X-dataset_size\n",
    "                \n",
    "            # If the data is not exhausted \n",
    "            else:\n",
    "                # Take X rows\n",
    "                records = dataset.iloc[counter:(counter+X)]\n",
    "                # Update sequence tracking counter\n",
    "                data_tracking[idx][1] = counter + X\n",
    "            \n",
    "            # Add all rows to the list\n",
    "            rows = rows + records.to_dict('records')\n",
    "        \n",
    "        # Send data together with timestamp\n",
    "        data = {\n",
    "            'ts': int(time.time()), \n",
    "            'data': rows\n",
    "        }\n",
    "        publish_message(producer, topic, data)\n",
    "        \n",
    "        # Rest for 5 seconds\n",
    "        sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
